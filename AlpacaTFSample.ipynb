{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlpacaTFSample.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QROST/AlpacaPlayground/blob/main/AlpacaTFSample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t56BN2JXXn_K",
        "outputId": "b3c07420-5a53-4e9b-d2c2-af4942364005",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install alpaca-trade-api\n",
        "!pip install --upgrade mplfinance\n",
        "!wget https://launchpad.net/~mario-mariomedina/+archive/ubuntu/talib/+files/libta-lib0_0.4.0-oneiric1_amd64.deb -qO libta.deb\n",
        "!wget https://launchpad.net/~mario-mariomedina/+archive/ubuntu/talib/+files/ta-lib0-dev_0.4.0-oneiric1_amd64.deb -qO ta.deb\n",
        "!dpkg -i libta.deb ta.deb\n",
        "!pip install ta-lib"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting alpaca-trade-api\n",
            "  Downloading https://files.pythonhosted.org/packages/cf/01/ee98cac996038ea7ec5b53dfa8cd8d681d92ee6e2d9f878f8f29e573f5ed/alpaca_trade_api-0.51.0-py3-none-any.whl\n",
            "Requirement already satisfied: requests<3,>2 in /usr/local/lib/python3.6/dist-packages (from alpaca-trade-api) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from alpaca-trade-api) (1.1.3)\n",
            "Collecting websockets<9,>=8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/d9/856af84843912e2853b1b6e898ac8b802989fcf9ecf8e8445a1da263bf3b/websockets-8.1-cp36-cp36m-manylinux2010_x86_64.whl (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 4.0MB/s \n",
            "\u001b[?25hCollecting websocket-client<1,>=0.56.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 22.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.26,>1.24 in /usr/local/lib/python3.6/dist-packages (from alpaca-trade-api) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>2->alpaca-trade-api) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>2->alpaca-trade-api) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>2->alpaca-trade-api) (2020.6.20)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas->alpaca-trade-api) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->alpaca-trade-api) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->alpaca-trade-api) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from websocket-client<1,>=0.56.0->alpaca-trade-api) (1.15.0)\n",
            "Installing collected packages: websockets, websocket-client, alpaca-trade-api\n",
            "Successfully installed alpaca-trade-api-0.51.0 websocket-client-0.57.0 websockets-8.1\n",
            "Collecting mplfinance\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/01/3418bb0c9952d4a3c24893e883df8e39065d7a13e7d60ae4f139a9eafc78/mplfinance-0.12.7a0-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from mplfinance) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from mplfinance) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mplfinance) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mplfinance) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mplfinance) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mplfinance) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mplfinance) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->mplfinance) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->mplfinance) (1.15.0)\n",
            "Installing collected packages: mplfinance\n",
            "Successfully installed mplfinance-0.12.7a0\n",
            "Selecting previously unselected package libta-lib0.\n",
            "(Reading database ... 144628 files and directories currently installed.)\n",
            "Preparing to unpack libta.deb ...\n",
            "Unpacking libta-lib0 (0.4.0-oneiric1) ...\n",
            "Selecting previously unselected package ta-lib0-dev.\n",
            "Preparing to unpack ta.deb ...\n",
            "Unpacking ta-lib0-dev (0.4.0-oneiric1) ...\n",
            "Setting up libta-lib0 (0.4.0-oneiric1) ...\n",
            "Setting up ta-lib0-dev (0.4.0-oneiric1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Collecting ta-lib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/cf/681911aa31e04ba171ab4d523a412f4a746e30d3eacb1738799d181e028b/TA-Lib-0.4.19.tar.gz (267kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ta-lib) (1.18.5)\n",
            "Building wheels for collected packages: ta-lib\n",
            "  Building wheel for ta-lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta-lib: filename=TA_Lib-0.4.19-cp36-cp36m-linux_x86_64.whl size=1437792 sha256=96bb9c5f22f8e0a9c682d298743f3afe0050d103b5876e158cd192e97479c9fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/f6/12/3d1ccd06caadd8fa47e016991dd0d27f1163bb260f1854e2ff\n",
            "Successfully built ta-lib\n",
            "Installing collected packages: ta-lib\n",
            "Successfully installed ta-lib-0.4.19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPhPBaw6XZ4L"
      },
      "source": [
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import talib\n",
        "import alpaca_trade_api as tradeapi\n",
        "import pandas\n",
        "from time import sleep\n",
        "import os\n",
        "\n",
        "\n",
        "# Creates dataset folders in directory script is run from\n",
        "try:\n",
        "    os.stat(\"./train\")\n",
        "    os.stat(\"./eval\")\n",
        "except BaseException:\n",
        "    os.mkdir(\"./train\")\n",
        "    os.mkdir(\"./eval\")\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbxW6voS1xMh"
      },
      "source": [
        "#paper trade account\n",
        "api = tradeapi.REST(\n",
        "    \"PKW1DKS7S7VY873SRVCZ\",\n",
        "    \"Xi6LgmUGtakBizsSVfb3o3os9Im4v7s0R8gOn4GO\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i533XephXlPE"
      },
      "source": [
        "\n",
        "# api = tradeapi.REST(key_id= < your key id >, secret_key= < your secret\n",
        "# key > )\n",
        "\n",
        "barTimeframe = \"1D\"  # 1Min, 5Min, 15Min, 1H, 1D\n",
        "\n",
        "assetList = ['NVDA','MSFT','AMD','TRMB']\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPAWmO_DbzPo"
      },
      "source": [
        "\n",
        "# ISO8601 date format\n",
        "trainStartDate = \"2015-01-01T00:00:00.000Z\"\n",
        "trainEndDate = \"2017-06-01T00:00:00.000Z\"\n",
        "evalStartDate = \"2017-06-01T00:00:00.000Z\"\n",
        "evalEndDate = \"2020-06-01T00:00:00.000Z\"\n",
        "\n",
        "targetLookaheadPeriod = 1\n",
        "startCutoffPeriod = 50  # Set to length of maximum period indicator\n",
        "\n",
        "# Tracks position in list of symbols to download\n",
        "iteratorPos = 0\n",
        "assetListLen = len(assetList)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fq75DnO02oZ0",
        "outputId": "5cc3f198-2479-4e0e-a097-e0fc83e4c42f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "while iteratorPos < assetListLen:\n",
        "    symbol = assetList[iteratorPos]\n",
        "    iteratorPos += 1\n",
        "    # Returns market data as a pandas dataframe\n",
        "    returned_data = api.get_barset(\n",
        "        symbol,\n",
        "        barTimeframe,\n",
        "        start=trainStartDate,\n",
        "        end=evalEndDate).df\n",
        "    # Processes all data into numpy arrays for use by talib\n",
        "    timeList = np.array(returned_data.index)\n",
        "    openList = np.array(returned_data[symbol]['open'].tolist(), dtype=np.float64)\n",
        "    print(openList)\n",
        "    #print(returned_data)\n",
        "\n",
        "    highList = np.array(returned_data[symbol]['high'].tolist(), dtype=np.float64)\n",
        "    lowList = np.array(returned_data[symbol]['low'].tolist(), dtype=np.float64)\n",
        "    closeList = np.array(returned_data[symbol]['close'].tolist(), dtype=np.float64)\n",
        "    volumeList = np.array(returned_data[symbol]['volume'].tolist(), dtype=np.float64)\n",
        "    # Adjusts data lists due to the reward function look ahead period\n",
        "    shiftedTimeList = timeList[:-targetLookaheadPeriod]\n",
        "    shiftedClose = closeList[targetLookaheadPeriod:]\n",
        "    highList = highList[:-targetLookaheadPeriod]\n",
        "    lowList = lowList[:-targetLookaheadPeriod]\n",
        "    closeList = closeList[:-targetLookaheadPeriod]\n",
        "    # Calculate trading indicators\n",
        "    RSI14 = talib.RSI(closeList, 14)\n",
        "    RSI50 = talib.RSI(closeList, 50)\n",
        "    STOCH14K, STOCH14D = talib.STOCH(\n",
        "        highList, lowList, closeList, fastk_period=14, slowk_period=3, slowd_period=3)\n",
        "    # Calulate network target/ reward function for training\n",
        "    closeDifference = shiftedClose - closeList\n",
        "    closeDifferenceLen = len(closeDifference)\n",
        "    # Creates a binary output if the market moves up or down, for use as\n",
        "    # one-hot labels\n",
        "\n",
        "    longOutput = np.zeros(closeDifferenceLen)\n",
        "    longOutput[closeDifference >= 0] = 1\n",
        "    shortOutput = np.zeros(closeDifferenceLen)\n",
        "    shortOutput[closeDifference < 0] = 1\n",
        "    # Constructs the dataframe and writes to CSV file\n",
        "    outputDF = {\n",
        "        \"close\": closeList,  # Not to be included in network training, only for later analysis\n",
        "        \"RSI14\": RSI14,\n",
        "        \"RSI50\": RSI50,\n",
        "        \"STOCH14K\": STOCH14K,\n",
        "        \"STOCH14D\": STOCH14D,\n",
        "        \"longOutput\": longOutput,\n",
        "        \"shortOutput\": shortOutput\n",
        "    }\n",
        "    # Makes sure the dataframe columns don't get mixed up\n",
        "    columnOrder = [\"close\", \"RSI14\", \"RSI50\", \"STOCH14K\",\n",
        "                    \"STOCH14D\", \"longOutput\", \"shortOutput\"]\n",
        "    outputDF = pandas.DataFrame(\n",
        "        data=outputDF,\n",
        "        index=shiftedTimeList,\n",
        "        columns=columnOrder)[\n",
        "        startCutoffPeriod:]\n",
        "    # Splits data into training and evaluation sets\n",
        "    trainingDF = outputDF[outputDF.index < evalStartDate]\n",
        "    evalDF = outputDF[outputDF.index >= evalStartDate]\n",
        "\n",
        "    if (len(trainingDF) > 0 and len(evalDF) > 0):\n",
        "        print(\"writing \" + str(symbol) +\n",
        "              \", data len: \" + str(len(closeList)))\n",
        "\n",
        "        trainingDF.to_csv(\"./train/\" + symbol + \".csv\", index_label=\"date\")\n",
        "        evalDF.to_csv(\"./eval/\" + symbol + \".csv\", index_label=\"date\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 20.4   20.13  20.13 ... 345.   336.49 342.18]\n",
            "writing NVDA, data len: 1361\n",
            "[ 46.73  46.66  46.37 ... 180.2  180.74 182.73]\n",
            "writing MSFT, data len: 1361\n",
            "[ 2.64  2.7   2.67 ... 53.27 52.25 52.07]\n",
            "writing AMD, data len: 1361\n",
            "[27.13 26.7  26.8  ... 41.84 42.59 40.57]\n",
            "writing TRMB, data len: 1359\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrHK82SRX9td"
      },
      "source": [
        "2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32TlwqCFX-rQ"
      },
      "source": [
        "import argparse\n",
        "import sys\n",
        "import tempfile\n",
        "from time import time\n",
        "import random\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "\n",
        "import pandas\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tfc\n",
        "from sklearn import metrics\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuCgLuuvbluO"
      },
      "source": [
        "\n",
        "# model settings\n",
        "# Static seed to allow for reproducability between training runs\n",
        "tf.random.set_seed(12345)\n",
        "trainingCycles = 500000  # Number of training steps before ending\n",
        "batchSize = 1000  # Number of examples per training batch\n",
        "summarySteps = 1000  # Number of training steps between each summary\n",
        "dropout = 0.5  # Node dropout for training\n",
        "nodeLayout = [40, 30, 20, 10]  # Layout of nodes in each layer\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuzGLqYfGx5O"
      },
      "source": [
        "\n",
        "mainDirectory = str(\"./model_1/\")\n",
        "\n",
        "trainFiles = [f for f in listdir(\"./train/\") if isfile(join(\"./train/\", f))]\n",
        "evalFiles = [f for f in listdir(\"./eval/\") if isfile(join(\"./eval/\", f))]\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfGcQeIRHfPb"
      },
      "source": [
        "\n",
        "# Initialises data arrays\n",
        "trainDataX = np.empty([0, 4])\n",
        "trainDataY = np.empty([0, 2])\n",
        "evalDataX = np.empty([0, 4])\n",
        "evalDataY = np.empty([0, 2])\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHsBRynIHhav",
        "outputId": "85438d14-7d5c-42e5-8aec-5f287c89325c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "# Reads training data into memory\n",
        "readPos = 0\n",
        "for fileName in trainFiles:\n",
        "    importedData = pandas.read_csv(\"./train/\" + fileName, sep=',')\n",
        "\n",
        "    xValuesDF = importedData[[\"RSI14\", \"RSI50\", \"STOCH14K\", \"STOCH14D\"]]\n",
        "    yValuesDF = importedData[[\"longOutput\", \"shortOutput\"]]\n",
        "\n",
        "    xValues = np.array(xValuesDF.values.tolist())\n",
        "    yValues = np.array(yValuesDF.values.tolist())\n",
        "\n",
        "    trainDataX = np.concatenate([trainDataX, xValues], axis=0)\n",
        "    trainDataY = np.concatenate([trainDataY, yValues], axis=0)\n",
        "\n",
        "    if readPos % 50 == 0 and readPos > 0:\n",
        "        print(\"Loaded \" + str(readPos) + \" training files\")\n",
        "\n",
        "    readPos += 1\n",
        "print(\"\\n\\n\")\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDWcfZqXIAtq",
        "outputId": "ae35142f-d6e6-4b4c-e60a-60537989437a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "# Reads evalutation data into memory\n",
        "readPos = 0\n",
        "for fileName in evalFiles:\n",
        "    importedData = pandas.read_csv(\"./eval/\" + fileName, sep=',')\n",
        "\n",
        "    xValuesDF = importedData[[\"RSI14\", \"RSI50\", \"STOCH14K\", \"STOCH14D\"]]\n",
        "    yValuesDF = importedData[[\"longOutput\", \"shortOutput\"]]\n",
        "\n",
        "    xValues = np.array(xValuesDF.values.tolist())\n",
        "    yValues = np.array(yValuesDF.values.tolist())\n",
        "\n",
        "    evalDataX = np.concatenate([evalDataX, xValues], axis=0)\n",
        "    evalDataY = np.concatenate([evalDataY, yValues], axis=0)\n",
        "\n",
        "    if readPos % 50 == 0 and readPos > 0:\n",
        "        print(\"Loaded \" + str(readPos) + \" training files\")\n",
        "\n",
        "    readPos += 1\n",
        "print(\"\\n\\n\")\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POVUrKKqIL5n"
      },
      "source": [
        "# used to sample batches from your data for training\n",
        "def createTrainingBatch(amount):\n",
        "\n",
        "    randomBatchPos = np.random.randint(0, trainDataX.shape[0], amount)\n",
        "\n",
        "    xOut = trainDataX[randomBatchPos]\n",
        "    yOut = trainDataY[randomBatchPos]\n",
        "\n",
        "    return xOut, yOut"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxrqpHWJIN_6"
      },
      "source": [
        "tfc.logging.set_verbosity(tfc.logging.INFO)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHcOQN4tHlOm"
      },
      "source": [
        "# ML training and evaluation functions\n",
        "def train_tfc():\n",
        "    globalStepTensor = tfc.Variable(0, trainable=False, name='global_step')\n",
        "\n",
        "    sess = tfc.InteractiveSession()\n",
        "\n",
        "    # placeholder for the input features\n",
        "    x = tfc.placeholder(tfc.float32, [None, 4])\n",
        "    # placeholder for the one-hot labels\n",
        "    y = tfc.placeholder(tfc.float32, [None, 2])\n",
        "    # placeholder for node dropout rate\n",
        "    internalDropout = tfc.placeholder(tfc.float32, None)\n",
        "\n",
        "    net = x  # input layer is the trading indicators\n",
        "\n",
        "    # Creates the neural network model\n",
        "    with tfc.name_scope('network'):\n",
        "        # Initialises each layer in the network\n",
        "        layerPos = 0\n",
        "        for units in nodeLayout:\n",
        "            net = tfc.layers.dense(\n",
        "                net,\n",
        "                units=units,\n",
        "                activation=tfc.nn.tanh,\n",
        "                name=str(\n",
        "                    \"dense\" +\n",
        "                    str(units) +\n",
        "                    \"_\" +\n",
        "                    str(layerPos)))  # adds each layer to the networm as specified by nodeLayout\n",
        "            # dropout layer after each layer\n",
        "            net = tfc.layers.dropout(net, rate=internalDropout)\n",
        "            layerPos += 1\n",
        "\n",
        "    logits = tfc.layers.dense(\n",
        "        net, 2, activation=tfc.nn.softmax)  # network output\n",
        "\n",
        "    with tfc.name_scope('lossFunction'):\n",
        "        cross_entropy_loss = tfc.reduce_mean(\n",
        "            tfc.nn.softmax_cross_entropy_with_logits_v2(\n",
        "                labels=y,\n",
        "                logits=logits))  # on NO account put this within a name scope - tensorboard shits itself\n",
        "\n",
        "    with tfc.name_scope('trainingStep'):\n",
        "        tfc.summary.scalar('crossEntropyLoss', cross_entropy_loss)\n",
        "        trainStep = tfc.train.AdamOptimizer(0.0001).minimize(\n",
        "            cross_entropy_loss, global_step=globalStepTensor)\n",
        "\n",
        "    with tfc.name_scope('accuracy'):\n",
        "        correctPrediction = tfc.equal(tfc.argmax(logits, 1), tfc.argmax(y, 1))\n",
        "        accuracy = tfc.reduce_mean(tfc.cast(correctPrediction, tfc.float32))\n",
        "        tfc.summary.scalar('accuracy', accuracy)\n",
        "\n",
        "    merged = tfc.summary.merge_all()\n",
        "    trainWriter = tfc.summary.FileWriter(\n",
        "        mainDirectory + '/train', sess.graph, flush_secs=1, max_queue=2)\n",
        "    evalWriter = tfc.summary.FileWriter(\n",
        "        mainDirectory + '/eval', sess.graph, flush_secs=1, max_queue=2)\n",
        "    tfc.global_variables_initializer().run()\n",
        "\n",
        "    # Saves the model at defined checkpoints and loads any available model at\n",
        "    # start-up\n",
        "    saver = tfc.train.Saver(max_to_keep=2, name=\"checkpoint\")\n",
        "    path = tfc.train.get_checkpoint_state(mainDirectory)\n",
        "    if path is not None:\n",
        "        saver.restore(sess, tfc.train.latest_checkpoint(mainDirectory))\n",
        "\n",
        "    lastTime = time()\n",
        "    while tfc.train.global_step(sess, globalStepTensor) <= trainingCycles:\n",
        "        globalStep = tfc.train.global_step(sess, globalStepTensor)\n",
        "\n",
        "        # generates batch for each training cycle\n",
        "        xFeed, yFeed = createTrainingBatch(batchSize)\n",
        "\n",
        "        # Record summaries and accuracy on both train and eval data\n",
        "        if globalStep % summarySteps == 0:\n",
        "            currentTime = time()\n",
        "            totalTime = (currentTime - lastTime)\n",
        "            print(str(totalTime) + \" seconds, \" +\n",
        "                  str(summarySteps / totalTime) + \" steps/sec\")\n",
        "            lastTime = currentTime\n",
        "\n",
        "            summary, accuracyOut, _ = sess.run([\n",
        "                merged,\n",
        "                accuracy,\n",
        "                trainStep\n",
        "            ],\n",
        "                feed_dict={\n",
        "                    x: xFeed,\n",
        "                    y: yFeed,\n",
        "                    internalDropout: dropout\n",
        "                })\n",
        "            trainWriter.add_summary(summary, globalStep)\n",
        "            trainWriter.flush()\n",
        "            print('Train accuracy at step %s: %s' % (globalStep, accuracyOut))\n",
        "\n",
        "            summary, accuracyOut = sess.run([\n",
        "                merged,\n",
        "                accuracy,\n",
        "            ],\n",
        "                feed_dict={\n",
        "                    x: evalDataX,\n",
        "                    y: evalDataY,\n",
        "                    internalDropout: 0\n",
        "                })\n",
        "            evalWriter.add_summary(summary, globalStep)\n",
        "            evalWriter.flush()\n",
        "            print('Eval accuracy at step %s: %s' % (globalStep, accuracyOut))\n",
        "\n",
        "            print(\"\\n\\n\")\n",
        "            saver.save(sess, save_path=str(mainDirectory + \"model\"),\n",
        "                       global_step=globalStep)  # saves a snapshot of the model\n",
        "\n",
        "        else:  # Training cycle\n",
        "            _ = sess.run(\n",
        "                [trainStep], feed_dict={\n",
        "                    x: xFeed,\n",
        "                    y: yFeed,\n",
        "                    internalDropout: dropout\n",
        "                })\n",
        "\n",
        "    trainWriter.close()\n",
        "    evalWriter.close()\n",
        "\n",
        "\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcJVF-yjIH5w",
        "outputId": "04781326-9ef2-451c-9f9f-23788e094cb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tfc.disable_eager_execution()\n",
        "train_tfc()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-48-d88d7cef9a8d>:29: dense (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From <ipython-input-48-d88d7cef9a8d>:31: dropout (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1751: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.010373353958129883 seconds, 96400.83660851778 steps/sec\n",
            "Train accuracy at step 0: 0.493\n",
            "Eval accuracy at step 0: 0.45647842\n",
            "\n",
            "\n",
            "\n",
            "3.001831293106079 seconds, 333.12998045445516 steps/sec\n",
            "Train accuracy at step 1000: 0.529\n",
            "Eval accuracy at step 1000: 0.5345515\n",
            "\n",
            "\n",
            "\n",
            "2.8076281547546387 seconds, 356.1725217445652 steps/sec\n",
            "Train accuracy at step 2000: 0.548\n",
            "Eval accuracy at step 2000: 0.5299003\n",
            "\n",
            "\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "2.8122189044952393 seconds, 355.5910951318665 steps/sec\n",
            "Train accuracy at step 3000: 0.569\n",
            "Eval accuracy at step 3000: 0.52890366\n",
            "\n",
            "\n",
            "\n",
            "2.8926992416381836 seconds, 345.69788162065663 steps/sec\n",
            "Train accuracy at step 4000: 0.54\n",
            "Eval accuracy at step 4000: 0.5328904\n",
            "\n",
            "\n",
            "\n",
            "2.7982494831085205 seconds, 357.36627703728533 steps/sec\n",
            "Train accuracy at step 5000: 0.586\n",
            "Eval accuracy at step 5000: 0.5375415\n",
            "\n",
            "\n",
            "\n",
            "2.803542375564575 seconds, 356.69159443278284 steps/sec\n",
            "Train accuracy at step 6000: 0.556\n",
            "Eval accuracy at step 6000: 0.5332226\n",
            "\n",
            "\n",
            "\n",
            "2.809389352798462 seconds, 355.9492382228507 steps/sec\n",
            "Train accuracy at step 7000: 0.563\n",
            "Eval accuracy at step 7000: 0.52491695\n",
            "\n",
            "\n",
            "\n",
            "2.803913116455078 seconds, 356.6444317162996 steps/sec\n",
            "Train accuracy at step 8000: 0.578\n",
            "Eval accuracy at step 8000: 0.520598\n",
            "\n",
            "\n",
            "\n",
            "2.8499948978424072 seconds, 350.87782113471553 steps/sec\n",
            "Train accuracy at step 9000: 0.58\n",
            "Eval accuracy at step 9000: 0.5335548\n",
            "\n",
            "\n",
            "\n",
            "2.8160877227783203 seconds, 355.10257436633094 steps/sec\n",
            "Train accuracy at step 10000: 0.598\n",
            "Eval accuracy at step 10000: 0.520598\n",
            "\n",
            "\n",
            "\n",
            "2.8034634590148926 seconds, 356.7016351807166 steps/sec\n",
            "Train accuracy at step 11000: 0.58\n",
            "Eval accuracy at step 11000: 0.52956814\n",
            "\n",
            "\n",
            "\n",
            "2.7795310020446777 seconds, 359.7729254555464 steps/sec\n",
            "Train accuracy at step 12000: 0.553\n",
            "Eval accuracy at step 12000: 0.5255814\n",
            "\n",
            "\n",
            "\n",
            "2.7918601036071777 seconds, 358.1841363426363 steps/sec\n",
            "Train accuracy at step 13000: 0.601\n",
            "Eval accuracy at step 13000: 0.5189369\n",
            "\n",
            "\n",
            "\n",
            "2.802464485168457 seconds, 356.8287859818818 steps/sec\n",
            "Train accuracy at step 14000: 0.609\n",
            "Eval accuracy at step 14000: 0.5229236\n",
            "\n",
            "\n",
            "\n",
            "2.81367564201355 seconds, 355.40699328241345 steps/sec\n",
            "Train accuracy at step 15000: 0.592\n",
            "Eval accuracy at step 15000: 0.5189369\n",
            "\n",
            "\n",
            "\n",
            "2.797683000564575 seconds, 357.4386375433525 steps/sec\n",
            "Train accuracy at step 16000: 0.604\n",
            "Eval accuracy at step 16000: 0.5215947\n",
            "\n",
            "\n",
            "\n",
            "2.8161635398864746 seconds, 355.09301425027047 steps/sec\n",
            "Train accuracy at step 17000: 0.603\n",
            "Eval accuracy at step 17000: 0.51262456\n",
            "\n",
            "\n",
            "\n",
            "2.801981210708618 seconds, 356.89033037701955 steps/sec\n",
            "Train accuracy at step 18000: 0.602\n",
            "Eval accuracy at step 18000: 0.5146179\n",
            "\n",
            "\n",
            "\n",
            "2.8158609867095947 seconds, 355.1311675966382 steps/sec\n",
            "Train accuracy at step 19000: 0.603\n",
            "Eval accuracy at step 19000: 0.51495016\n",
            "\n",
            "\n",
            "\n",
            "2.813765048980713 seconds, 355.3957002779071 steps/sec\n",
            "Train accuracy at step 20000: 0.641\n",
            "Eval accuracy at step 20000: 0.5179402\n",
            "\n",
            "\n",
            "\n",
            "2.7934865951538086 seconds, 357.97558568378963 steps/sec\n",
            "Train accuracy at step 21000: 0.626\n",
            "Eval accuracy at step 21000: 0.51428574\n",
            "\n",
            "\n",
            "\n",
            "2.810506582260132 seconds, 355.80774167617415 steps/sec\n",
            "Train accuracy at step 22000: 0.618\n",
            "Eval accuracy at step 22000: 0.50498337\n",
            "\n",
            "\n",
            "\n",
            "2.805302381515503 seconds, 356.4678113094432 steps/sec\n",
            "Train accuracy at step 23000: 0.62\n",
            "Eval accuracy at step 23000: 0.51328903\n",
            "\n",
            "\n",
            "\n",
            "2.789885997772217 seconds, 358.43758519112293 steps/sec\n",
            "Train accuracy at step 24000: 0.627\n",
            "Eval accuracy at step 24000: 0.51196015\n",
            "\n",
            "\n",
            "\n",
            "2.8548412322998047 seconds, 350.2821763557126 steps/sec\n",
            "Train accuracy at step 25000: 0.591\n",
            "Eval accuracy at step 25000: 0.51096344\n",
            "\n",
            "\n",
            "\n",
            "2.804431438446045 seconds, 356.57851580572316 steps/sec\n",
            "Train accuracy at step 26000: 0.63\n",
            "Eval accuracy at step 26000: 0.50963455\n",
            "\n",
            "\n",
            "\n",
            "2.76851749420166 seconds, 361.2041470188953 steps/sec\n",
            "Train accuracy at step 27000: 0.655\n",
            "Eval accuracy at step 27000: 0.51328903\n",
            "\n",
            "\n",
            "\n",
            "2.790938138961792 seconds, 358.3024596783046 steps/sec\n",
            "Train accuracy at step 28000: 0.618\n",
            "Eval accuracy at step 28000: 0.50863785\n",
            "\n",
            "\n",
            "\n",
            "2.807964563369751 seconds, 356.1298504422474 steps/sec\n",
            "Train accuracy at step 29000: 0.639\n",
            "Eval accuracy at step 29000: 0.51495016\n",
            "\n",
            "\n",
            "\n",
            "2.924508571624756 seconds, 341.93779074630464 steps/sec\n",
            "Train accuracy at step 30000: 0.651\n",
            "Eval accuracy at step 30000: 0.50730896\n",
            "\n",
            "\n",
            "\n",
            "2.876474142074585 seconds, 347.64783224464344 steps/sec\n",
            "Train accuracy at step 31000: 0.639\n",
            "Eval accuracy at step 31000: 0.5089701\n",
            "\n",
            "\n",
            "\n",
            "2.856858491897583 seconds, 350.0348382099177 steps/sec\n",
            "Train accuracy at step 32000: 0.593\n",
            "Eval accuracy at step 32000: 0.50664455\n",
            "\n",
            "\n",
            "\n",
            "2.8383026123046875 seconds, 352.32324970028657 steps/sec\n",
            "Train accuracy at step 33000: 0.673\n",
            "Eval accuracy at step 33000: 0.50963455\n",
            "\n",
            "\n",
            "\n",
            "2.855146646499634 seconds, 350.2447067739882 steps/sec\n",
            "Train accuracy at step 34000: 0.617\n",
            "Eval accuracy at step 34000: 0.51262456\n",
            "\n",
            "\n",
            "\n",
            "2.8473267555236816 seconds, 351.2066179478862 steps/sec\n",
            "Train accuracy at step 35000: 0.649\n",
            "Eval accuracy at step 35000: 0.5136213\n",
            "\n",
            "\n",
            "\n",
            "2.88608455657959 seconds, 346.49019472428023 steps/sec\n",
            "Train accuracy at step 36000: 0.673\n",
            "Eval accuracy at step 36000: 0.510299\n",
            "\n",
            "\n",
            "\n",
            "2.844748020172119 seconds, 351.5249832002681 steps/sec\n",
            "Train accuracy at step 37000: 0.641\n",
            "Eval accuracy at step 37000: 0.52093023\n",
            "\n",
            "\n",
            "\n",
            "2.8805346488952637 seconds, 347.1577751663282 steps/sec\n",
            "Train accuracy at step 38000: 0.654\n",
            "Eval accuracy at step 38000: 0.5156146\n",
            "\n",
            "\n",
            "\n",
            "2.844344139099121 seconds, 351.5748977958505 steps/sec\n",
            "Train accuracy at step 39000: 0.648\n",
            "Eval accuracy at step 39000: 0.5152824\n",
            "\n",
            "\n",
            "\n",
            "2.8492250442504883 seconds, 350.9726274580947 steps/sec\n",
            "Train accuracy at step 40000: 0.659\n",
            "Eval accuracy at step 40000: 0.51196015\n",
            "\n",
            "\n",
            "\n",
            "2.8211076259613037 seconds, 354.4707017901332 steps/sec\n",
            "Train accuracy at step 41000: 0.662\n",
            "Eval accuracy at step 41000: 0.5106312\n",
            "\n",
            "\n",
            "\n",
            "2.855774164199829 seconds, 350.1677452426264 steps/sec\n",
            "Train accuracy at step 42000: 0.626\n",
            "Eval accuracy at step 42000: 0.5059801\n",
            "\n",
            "\n",
            "\n",
            "2.90197491645813 seconds, 344.5929164751373 steps/sec\n",
            "Train accuracy at step 43000: 0.678\n",
            "Eval accuracy at step 43000: 0.50664455\n",
            "\n",
            "\n",
            "\n",
            "3.039450168609619 seconds, 329.00687444316446 steps/sec\n",
            "Train accuracy at step 44000: 0.664\n",
            "Eval accuracy at step 44000: 0.5099668\n",
            "\n",
            "\n",
            "\n",
            "2.968320846557617 seconds, 336.8908051701039 steps/sec\n",
            "Train accuracy at step 45000: 0.673\n",
            "Eval accuracy at step 45000: 0.50863785\n",
            "\n",
            "\n",
            "\n",
            "2.9254956245422363 seconds, 341.82242202343883 steps/sec\n",
            "Train accuracy at step 46000: 0.682\n",
            "Eval accuracy at step 46000: 0.51262456\n",
            "\n",
            "\n",
            "\n",
            "2.8308329582214355 seconds, 353.2529169888862 steps/sec\n",
            "Train accuracy at step 47000: 0.659\n",
            "Eval accuracy at step 47000: 0.5089701\n",
            "\n",
            "\n",
            "\n",
            "2.809936285018921 seconds, 355.8799554749571 steps/sec\n",
            "Train accuracy at step 48000: 0.677\n",
            "Eval accuracy at step 48000: 0.5046512\n",
            "\n",
            "\n",
            "\n",
            "2.854874610900879 seconds, 350.2780809292503 steps/sec\n",
            "Train accuracy at step 49000: 0.649\n",
            "Eval accuracy at step 49000: 0.5116279\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}